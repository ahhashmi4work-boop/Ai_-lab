{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2cd11f",
   "metadata": {},
   "source": [
    "# Read CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45506a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ccc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('read.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a433d2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Resume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b596c3bb-e32a-409b-ab5b-8191b5352e79",
       "rows": [
        [
         "0",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\n• FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "1",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "2",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "3",
         "Data Science",
         "Skills • R • Python • SAP HANA • Tableau • SAP HANA SQL • SAP HANA PAL • MS SQL • SAP Lumira • C# • Linear Programming • Data Modelling • Advance Analytics • SCM Analytics • Retail Analytics •Social Media Analytics • NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\n• Extract data from client systems across geographies.\r\n• Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\n• Gather data large enough to capture all English words\r\n• Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop ETL for data flow\r\n• Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop and deploy analytical models.\r\n• Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\n• Design & Develop HANA models for decomposition.\r\n• Develop data flow for forecast.\r\n• Developed various views for reporting of Customer/Sales/Funds.\r\n• Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\n• Involved in information gather phase.\r\n• Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\n• Developed various KPI's individually using complex SQL scripts in Calculation views.\r\n• Created procedures in HANA Database.\r\n• Took ownership and developed Dashboard functionality.\r\n• Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\n• Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\n• Create / Update database objects like tables, views, stored procedures, function, and packages\r\n• Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\n• Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\n• Responsible for Designing, developing and Normalization of database tables\r\n• Experience in performance tuning using SQL profiler.\r\n• Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "4",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "5",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "6",
         "Data Science",
         "Skills • Python • Tableau • Data Visualization • R Studio • Machine Learning • Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - • Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\n• Responsible for loading, extracting and validation of client data.\r\n• Worked on manipulating, cleaning & processing data using python.\r\n• Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - • Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\n• Manipulating, cleansing & processing data using Python, Excel and R.\r\n• Analyzed raw data, drawing conclusions & developing recommendations.\r\n• Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "7",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "8",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "9",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "10",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\n• FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "11",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "12",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "13",
         "Data Science",
         "Skills • R • Python • SAP HANA • Tableau • SAP HANA SQL • SAP HANA PAL • MS SQL • SAP Lumira • C# • Linear Programming • Data Modelling • Advance Analytics • SCM Analytics • Retail Analytics •Social Media Analytics • NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\n• Extract data from client systems across geographies.\r\n• Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\n• Gather data large enough to capture all English words\r\n• Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop ETL for data flow\r\n• Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop and deploy analytical models.\r\n• Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\n• Design & Develop HANA models for decomposition.\r\n• Develop data flow for forecast.\r\n• Developed various views for reporting of Customer/Sales/Funds.\r\n• Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\n• Involved in information gather phase.\r\n• Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\n• Developed various KPI's individually using complex SQL scripts in Calculation views.\r\n• Created procedures in HANA Database.\r\n• Took ownership and developed Dashboard functionality.\r\n• Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\n• Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\n• Create / Update database objects like tables, views, stored procedures, function, and packages\r\n• Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\n• Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\n• Responsible for Designing, developing and Normalization of database tables\r\n• Experience in performance tuning using SQL profiler.\r\n• Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "14",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "15",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "16",
         "Data Science",
         "Skills • Python • Tableau • Data Visualization • R Studio • Machine Learning • Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - • Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\n• Responsible for loading, extracting and validation of client data.\r\n• Worked on manipulating, cleaning & processing data using python.\r\n• Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - • Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\n• Manipulating, cleansing & processing data using Python, Excel and R.\r\n• Analyzed raw data, drawing conclusions & developing recommendations.\r\n• Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "17",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "18",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "19",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "20",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\n• FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "21",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "22",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "23",
         "Data Science",
         "Skills • R • Python • SAP HANA • Tableau • SAP HANA SQL • SAP HANA PAL • MS SQL • SAP Lumira • C# • Linear Programming • Data Modelling • Advance Analytics • SCM Analytics • Retail Analytics •Social Media Analytics • NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\n• Extract data from client systems across geographies.\r\n• Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\n• Gather data large enough to capture all English words\r\n• Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop ETL for data flow\r\n• Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop and deploy analytical models.\r\n• Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\n• Design & Develop HANA models for decomposition.\r\n• Develop data flow for forecast.\r\n• Developed various views for reporting of Customer/Sales/Funds.\r\n• Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\n• Involved in information gather phase.\r\n• Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\n• Developed various KPI's individually using complex SQL scripts in Calculation views.\r\n• Created procedures in HANA Database.\r\n• Took ownership and developed Dashboard functionality.\r\n• Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\n• Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\n• Create / Update database objects like tables, views, stored procedures, function, and packages\r\n• Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\n• Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\n• Responsible for Designing, developing and Normalization of database tables\r\n• Experience in performance tuning using SQL profiler.\r\n• Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "24",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "25",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "26",
         "Data Science",
         "Skills • Python • Tableau • Data Visualization • R Studio • Machine Learning • Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - • Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\n• Responsible for loading, extracting and validation of client data.\r\n• Worked on manipulating, cleaning & processing data using python.\r\n• Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - • Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\n• Manipulating, cleansing & processing data using Python, Excel and R.\r\n• Analyzed raw data, drawing conclusions & developing recommendations.\r\n• Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "27",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "28",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "29",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "30",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\n• FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "31",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "32",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "33",
         "Data Science",
         "Skills • R • Python • SAP HANA • Tableau • SAP HANA SQL • SAP HANA PAL • MS SQL • SAP Lumira • C# • Linear Programming • Data Modelling • Advance Analytics • SCM Analytics • Retail Analytics •Social Media Analytics • NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\n• Extract data from client systems across geographies.\r\n• Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\n• Gather data large enough to capture all English words\r\n• Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop ETL for data flow\r\n• Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop and deploy analytical models.\r\n• Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\n• Design & Develop HANA models for decomposition.\r\n• Develop data flow for forecast.\r\n• Developed various views for reporting of Customer/Sales/Funds.\r\n• Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\n• Involved in information gather phase.\r\n• Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\n• Developed various KPI's individually using complex SQL scripts in Calculation views.\r\n• Created procedures in HANA Database.\r\n• Took ownership and developed Dashboard functionality.\r\n• Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\n• Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\n• Create / Update database objects like tables, views, stored procedures, function, and packages\r\n• Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\n• Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\n• Responsible for Designing, developing and Normalization of database tables\r\n• Experience in performance tuning using SQL profiler.\r\n• Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "34",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "35",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "36",
         "Data Science",
         "Skills • Python • Tableau • Data Visualization • R Studio • Machine Learning • Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - • Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\n• Responsible for loading, extracting and validation of client data.\r\n• Worked on manipulating, cleaning & processing data using python.\r\n• Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - • Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\n• Manipulating, cleansing & processing data using Python, Excel and R.\r\n• Analyzed raw data, drawing conclusions & developing recommendations.\r\n• Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "37",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "38",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "39",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "40",
         "HR",
         "TECHNICAL SKILLS • Typewriting • TORA • SPSSEducation Details \r\nJanuary 2017 MBA  Chidambaram, Tamil Nadu SNS College of Engineering\r\nJanuary 2014 HSC   at SAV Higher Secondary School\r\n MBA   SNS College of Engineering\r\n SSLC Finance  at Kamaraj Matriculation School\r\nHR \r\n\r\n\r\nSkill Details \r\nHuman resource, Finance- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "41",
         "HR",
         "I.T. Skills • Windows XP, Ms Office (Word, Excel: Look-ups; Pivot table; other basic functions ; Power Point) • Saral Payment Package- payroll software • Internet ApplicationsEducation Details \r\nJanuary 2006 Bachelor in Hospitality Management International Hospitality Management  Queen Margaret University Edinburg\r\nJanuary 2006 diploma Hotel Management  International Institute of Hotel Management\r\nHR \r\n\r\n\r\nSkill Details \r\nHr Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Atri Developers\r\ndescription - • HR Payroll Statutory Compliance Performance Management\r\ncompany - \r\ndescription - Employee Relations and Administration: Creating industry specific Policies, Procedure, Forms, Formats, Letters, Checklists etc\r\n\r\nPayroll Management: Salary restructuring to process payroll of 600 employees.\r\n• Validation of all input (Attendance, Leaves, and Salaries) before starting salary process.\r\n• Processing accurate & error free salary of employees.\r\n• Responsible for compensation and benefits administration.\r\n• Coordinate with Accounts team for salary processing.\r\n• Attendance & Leave record management\r\n• Assuring prompt and satisfactory resolution of payroll related queries of all employees.\r\n\r\nStatutory Compliance Management:\r\n•  Manage various statutory compliance requirements (PF, ESIC, PT, Gratuity, TDS etc calculations, deduction, payment and return filing.\r\n• Generate statutory reports like Form 16, Form 24Q. Conducting session with employees on Statutory Policies and procedure, compliance related topics.\r\n• Shops and Commercial Establishments Act (S&E)\r\n• The Payment of Gratuity Act 1972\r\nRecruitment and Selection: Handling recruitment like job posting in naukri portal and coordination. Create annual manpower plan and budget. Screen and schedule preliminary interview. Arrange for employee orientation. Handling joining formalities and salary account opening formalities.\r\n\r\nPerformance Management: End to end facilitation of PMS starting from creating Job Description & Appraisal Forms to Disbursement of Letters. KRA setting, Mid-year reviews, Annual reviews, handling all appraisal activities (360 Degree)\r\n\r\nTraining and Development: Conduct training need analysis and arrange various training session.\r\n\r\nEmployee engagement and  Employee Welfare: Creation and deployment  of Sales  Rewards and Recognition Schemes, Periodic Interactive sessions like Monthly Birthday Celebration, Annual Day, Diwali Dhamaka, Offsite etc.\r\nWorking on Saral Payment Package- payroll software as well as on excel\r\nAssisting MD in HR works, offering suggestions and answering employee queries on payroll compliance related issues, other benefits (insurance, medical, reimbursement, ), full & final settlement of resigned employees."
        ],
        [
         "42",
         "HR",
         "Education Details \r\n BA   mumbai University\r\nHR \r\n\r\n\r\nSkill Details \r\nHr Operations- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Mumbai Monorail\r\ndescription - "
        ],
        [
         "43",
         "HR",
         "Education Details \r\nJune 2012 to May 2015 B.A Economics Chennai, Tamil Nadu Sdnbvc\r\nHr \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - Anything IT Solution\r\ndescription - Hr"
        ],
        [
         "44",
         "HR",
         "Education Details \r\nJune 2012 to May 2015 B.A Economics Chennai, Tamil Nadu Sdnbvc\r\nHr \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - Anything IT Solution\r\ndescription - Hr"
        ],
        [
         "45",
         "HR",
         "Education Details \r\n BBA   lovely professional university\r\nHR \r\n\r\n\r\nSkill Details \r\nCommunication- Exprience - 6 monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "46",
         "HR",
         "Education Details \r\n MBA   ACN College of engineering & mgt\r\nHR \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - HR Assistant\r\ndescription - "
        ],
        [
         "47",
         "HR",
         "KEY SKILLS: • Computerized accounting with tally • Sincere & hard working • Management accounting & income tax • Good communication & leadership • Two and four wheeler driving license • Internet & Ecommerce management COMPUTER SKILLS: • C Language • Web programing • Tally • Dbms Education Details \r\nJune 2017 to June 2019 Mba Finance/hr India Mlrit\r\nJune 2014 to June 2017 Bcom Computer Hyderabad, Telangana Osmania university\r\nJune 2012 to April 2014 Inter MEC India Srimedhav\r\nHr \r\n\r\nNani\r\nSkill Details \r\naccounting- Exprience - 6 months\r\nDATABASE MANAGEMENT SYSTEM- Exprience - 6 months\r\nDbms- Exprience - 6 months\r\nManagement accounting- Exprience - 6 months\r\nEcommerce- Exprience - 6 monthsCompany Details \r\ncompany - Valuelabs\r\ndescription - They will give the RRF form the required DLT then the hand over to RLT then scrum master will take the form from the RLT then scrum master will give the forms to trainee which we can work on the requirement till the candidate receive the offer from the company"
        ],
        [
         "48",
         "HR",
         "Training in Special Education (Certificate Course) Education Details \r\nJuly 2016 to October 2018 M.Sc Psychology with specialization in Organizational Behaviour Malappuram, Kerala Calicut University\r\nJuly 2013 to March 2016 BSc Psychology Thrissur Prajyoti Niketan College\r\nHR \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - \r\ndescription - I have done a 30 days internship in the HR department of Foster Hot Breads, KINFRA, Malappuram, Kerala and I have also done a 60 days internship at Santhwana Institute of Counselling and Psychotherapy, Cochin, Kerala as Counsellor"
        ],
        [
         "49",
         "HR",
         "Computer Knowledge: • Proficient in basic use of MS office • Microsoft Dynamics AX software • SAIBA softwareEducation Details \r\n MBA   Distance education Bharathiar University\r\n BE   PA College of Engineering and Technology\r\n HSC   R.V.G. Hr Sec School\r\n SSC   G.Hr.Sec School\r\nHR \r\n\r\nAdmin in Bharat\r\nSkill Details \r\nDYNAMICS- Exprience - 6 months\r\nDYNAMICS AX- Exprience - 6 months\r\nMICROSOFT DYNAMICS- Exprience - 6 months\r\nMICROSOFT DYNAMICS AX- Exprience - 6 months\r\nMS OFFICE- Exprience - 6 monthsCompany Details \r\ncompany - Sri Ramesh Gaarment\r\ndescription - Tirupur\r\n\r\nAdministration as well as clients service\r\nHere corporate companies only insured so that knowledge gathered about\r\nGarments, spinning mills\r\n\r\n• FEB 2018 to Still: Sri Ramesh Gaarment Tirupur.\r\n\r\nHR Activities\r\nAttendance maintenance, Time cards maintenance,\r\nStaffs and labors individual records maintenance\r\n\r\nProject:\r\n• Advanced automobile collision avoidance and blackbox in CAR"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 962
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills • R • Python • SAP HANA • Tableau • SAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: • Proficient in MS office (Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS • Quick learner, • Eagerness t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills • R • Python • SAP HANA • Tableau • SAP...\n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: • Proficient in MS office (Wo...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS • Quick learner, • Eagerness t...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f59cb1",
   "metadata": {},
   "source": [
    "# Print Top 5 rows of dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7b37be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Resume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "21b8a70f-6df4-45b9-94c4-49a803a64542",
       "rows": [
        [
         "0",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\n• FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "1",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "2",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "3",
         "Data Science",
         "Skills • R • Python • SAP HANA • Tableau • SAP HANA SQL • SAP HANA PAL • MS SQL • SAP Lumira • C# • Linear Programming • Data Modelling • Advance Analytics • SCM Analytics • Retail Analytics •Social Media Analytics • NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\n• Extract data from client systems across geographies.\r\n• Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\n• Gather data large enough to capture all English words\r\n• Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop ETL for data flow\r\n• Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\n• Design & Develop data models for reporting.\r\n• Develop and deploy analytical models.\r\n• Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\n• Design & Develop HANA models for decomposition.\r\n• Develop data flow for forecast.\r\n• Developed various views for reporting of Customer/Sales/Funds.\r\n• Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\n• Involved in information gather phase.\r\n• Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\n• Developed various KPI's individually using complex SQL scripts in Calculation views.\r\n• Created procedures in HANA Database.\r\n• Took ownership and developed Dashboard functionality.\r\n• Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\n• Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\n• Create / Update database objects like tables, views, stored procedures, function, and packages\r\n• Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\n• Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\n• Responsible for Designing, developing and Normalization of database tables\r\n• Experience in performance tuning using SQL profiler.\r\n• Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "4",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills • R • Python • SAP HANA • Tableau • SAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills • R • Python • SAP HANA • Tableau • SAP...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75641a",
   "metadata": {},
   "source": [
    "# Print Bottom 5 rows of dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1296c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Resume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7e311e9e-e84d-4095-80d8-08b4fe04b110",
       "rows": [
        [
         "957",
         "Testing",
         "Computer Skills: • Proficient in MS office (Word, Basic Excel, Power point) Strength: • Hard working, Loyalty & Creativity • Self-motivated, Responsible & Initiative • Good people management skill & positive attitude. • knowledge of windows, Internet.Education Details \r\n Bachelor of Electrical Engineering Electrical Engineering Nashik, Maharashtra Guru Gobind Singh College of Engineering and Research Centre\r\n Diploma Electrical Engineering Nashik, Maharashtra S. M. E. S. Polytechnic College\r\nTesting Engineer \r\n\r\n\r\nSkill Details \r\nEXCEL- Exprience - 6 months\r\nMS OFFICE- Exprience - 6 months\r\nWORD- Exprience - 6 monthsCompany Details \r\ncompany - \r\ndescription - Department: Testing\r\n\r\nResponsibilities: • To check ACB and VCB of  Circuit Breaker.\r\n• Following test conducted of Circuit Breaker as per drawing.\r\n1. To check breaker timing.\r\n2. To check contact resistance using contact resistance meter (CRM) 3. To check breaker insulation resistance (IR) 4. To check breaker rack out and rack in properly or not.\r\n5. To check closing and tripping operation work properly or not.\r\n• To check and following test conducted in MCC & PCC panel.\r\n1. Insulation Resistance (IR) test.\r\n2. Contact Resistance (CRM) test.\r\n3. To check connection on mcc & pcc panel as per drawing.\r\n• To check and following test conducted in transformer.\r\n1.  Insulation Resistance (IR) test.\r\n2.  Transformer Ratio test.\r\n3. Transformer Vector Group test.\r\n4. Magnetic Balance test.\r\n5. Magnetic Current test.\r\n6. To check the transformer tapping remotely as well as manually 7. To check the all alarm and tripping protection command work properly\r\nOr not as per circuit diagram.\r\n • To check and test conducted in HV cables.\r\n1. Hi-Pot test.\r\n2. Insulation resistance (IR) test.\r\n• To check the LV cables using megger (IR Test) • To check the relay connections as per circuit diagram.\r\nCreate the defects list which arising during the testing and try to find the solution to minimize the problem.\r\ncompany - TRANS POWER SOLUTIONS\r\ndescription - Lake-Site CO-Op.Soc. Adi Shankaracharya Marg,\r\nOpp. IIT Main Gate, Powai 400076."
        ],
        [
         "958",
         "Testing",
         "â Willingness to accept the challenges. â Positive thinking. â Good learner. â Team Player. DECLARATION: I hereby declare that the above mentioned information is correct up to my knowledge and I bear the responsibility for the correctness of the above mentioned particulars. Date: / / Name: Dongare Mandakini Murlidhar Signature: Education Details \r\nJune 2015 Electronics and Telecommunication Engineering  Kolhapur, Maharashtra Shivaji University\r\nJune 2012  Education  Secondary and Higher Secondary\r\n B.E. Electronics and Telecommunication  Jaywant College of Engineering and Management\r\nTesting Engineer \r\n\r\nElectronics Engineer - Abacus Electronics Pvt Ltd\r\nSkill Details \r\nLanguage - C, C++- Exprience - Less than 1 year months\r\nOperating Systems- Windows 7-8/NT/XP- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Abacus Electronics Pvt Ltd\r\ndescription - Duties:\r\nâ Perform electronic system testing for acceptance, compliance, warranty and other types.\r\nâ Develop test plan and procedure for electronic systems.\r\nâ Maintain complete and accurate documentations for system testing.\r\nâ Analyze and troubleshoot test defects in a timely fashion.\r\nâ Write system assembly instructions and resolve assembly issues accurately.\r\nâ Work with Supervisors to plan and coordinate test activities.\r\nâ Evaluate system performance and suggest improvements.\r\nâ Understand and interpret drawings, schematics, technical manuals and instructions.\r\nâ Also performed Hardware testing, debugging of hardware PCBs.\r\nâ Follow company policies and safely regulations.\r\nâ Work with cross-functional teams to complete assigned job duties within deadlines.\r\nâ Recommend process improvements to enhance testing efficiency.\r\ncompany - Minilec India Pvt Ltd , Pirangoot.\r\ndescription - ï¶\tTaking responsibility for the quality of a companyâs product.\r\nï¶\tWorking with the departmental manager, production staff and suppliers to ensure quality, they aim to minimize the cost of reworking or waste and maximize customer satisfaction with the product.\r\nï¶\tTo establish, implement and maintain quality management system to measure and control quality in the production process.\r\nï¶\tWork with the aim that to eliminate the causes of quality issues and reduce the risk of failure."
        ],
        [
         "959",
         "Testing",
         "PERSONAL SKILLS • Quick learner, • Eagerness to learn new things, • Competitive attitude, • Good leadership qualities, • Ability to deal with people diplomatically. PERSONAL DOSSIER Fathers Name: Dhanraj WaghEducation Details \r\nJanuary 2012 to January 2016 Bachelors of Engineering Engineering Pune, Maharashtra Pune University\r\nJanuary 2012 Higher Secondary Certificate  Nashik, Maharashtra SND College of Engineering and Research Center\r\nJanuary 2010 Secondary School Certificate  Yeola, Maharashtra Swami Muktanand Jr. College\r\n HSC   Maharashtra State Board\r\n SSC   Maharashtra State Bard\r\n BE  Rajapur, Uttar Pradesh Madhyamik Vidya Mandir Rajapur\r\nTesting and Quality Control Engineer \r\n\r\nTesting and Quality Control Engineer - M/S Rakesh Transformer Industries Pvt. Ltd\r\nSkill Details \r\nCompany Details \r\ncompany - M/S Rakesh Transformer Industries Pvt. Ltd\r\ndescription - Responsibilities:\r\n•     To conduct Routine test, Type Test (Temperature Rise Test), Special Test on Transformers as per IS & IEC up\r\n\r\nto - 10 MVA / 33 KV Class & preparing of its test reports.\r\n\r\n•     Routine tests, Type tests and Special tests as per IS 2026, IS 1180, IS 11171/IEC-60076- test\r\n\r\nManual/inspection plans of Power Transformers, Distribution Transformers, Inverter Duty, Converter Duty,\r\n\r\nMotor Duty Transformer, Furnace Transformer, Auto Transformers, Dry Type (VPI & CRT) LT Transformers,\r\n\r\nSpecial Transformers\r\n•     Testing Remote Tap Changer Cubicle (RTCC) Panel with OLTC and its operation ( CTR, Esun MR.)\r\n\r\n•     Functional Testing of Transformer Accessories ( BR, PRV, MOG, WTI, OTI and its Setting)\r\n\r\n•     In case any failure in testing analyses the root cause and submit the CAPA\r\n\r\n•     Assist the customer or their representative at the time of inspection.\r\n\r\n•     In process testing of winding, core assembly and core coil assembly.\r\n\r\n•     Handling 3rd party and Government Body's Inspection.\r\n\r\n•     Preparation of Daily Internal Testing Reports and send to concern.\r\n\r\n•     Support Certification Audits (ISO & BIS)\r\n\r\n•     Calibration/validation of tools, instruments, Measuring equipment's\r\n\r\n•     Suggest the client about proper maintenance of transformer\r\n•     Doing all documentation and Maintain Records and Analyze the Test Results and Maintain Testing Ledger\r\n\r\n•     In process Quality Inspection of Winding, Core assembly, Core Coil assembly as per Standard and as per\r\n\r\norganizational Norms.\r\n\r\n•     Pre Dispatch Quality Inspection of Complete Product.\r\n\r\n•     Implementation of, WHY-WHY analysis.\r\ncompany - M/S Silverline Electricals Pvt. Ltd\r\ndescription - Routine tests, Type tests (Temperature Rise Test) and Special tests as per IS 2026, IS 1180/ test\r\n\r\nManual/inspection plans of Distribution Transformer, Power Transformer\r\n\r\n•     Successfully handled Responsibilities of ERDA's testing.\r\n\r\n•     On site commissioning of Transformer.\r\n\r\n•     Assist the customer or their representative at the time of inspection.\r\n\r\n•     In process testing of winding, core assembly and core coil assembly.\r\n\r\n•     Successfully handling 3rd party and Government Body's Inspection\r\n\r\n•     Preparation of Daily Internal Testing Reports and send to concern.\r\n\r\n•     Suggest the client about proper maintenance of transformer"
        ],
        [
         "960",
         "Testing",
         "COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power Point, MS - Office, C, Protius (PCB Design), Multisim, Micro wind, Matlab, Keil, Latex, Basic I nternet Fundamentals, Software and Hardware Knowledge PROJECT DETAILS Diploma Project: Speed Control of DC Motor Using Heart Beats. Mini Project: Water Gardening System Using Solar Panel. Final Year BE Project: Iris Recognition system.Education Details \r\nJanuary 2016 BE EDUCATION Pune, Maharashtra PUNE University\r\nJanuary 2010 SSC   Maharashtra Board\r\nQuality Engineer \r\n\r\nQuality Engineer - Matrix Technologies\r\nSkill Details \r\nMATLAB- Exprience - 6 months\r\nPCB- Exprience - 6 months\r\nPCB DESIGN- Exprience - 6 monthsCompany Details \r\ncompany - Matrix Technologies\r\ndescription - \r\ncompany - RB Electronics\r\ndescription - "
        ],
        [
         "961",
         "Testing",
         "Skill Set OS Windows XP/7/8/8.1/10 Database MYSQL, sql server 2005, 2008 & 2012 Languages Core Java Web Technology HTML, CSS Testing Manual Testing, Database Testing Other Bug tracking and reporting, End user handling.Education Details \r\nJanuary 2016 MCS  Pune, Maharashtra P.V.P College Pravaranagar\r\nJanuary 2011 HSC   A.K.Junior College\r\nJanuary 2009 SSC   A.K.Mahavidyalya\r\nJR TESTING ENGINEER \r\n\r\nJR TESTING ENGINEER - M-Tech Innovations Ltd\r\nSkill Details \r\nTESTING- Exprience - 24 months\r\nWINDOWS XP- Exprience - 24 months\r\nCSS- Exprience - 6 months\r\nDATABASE- Exprience - 6 months\r\nDATABASE TESTING- Exprience - 6 monthsCompany Details \r\ncompany - M-Tech Innovations Ltd\r\ndescription - Responsibilities •     Analyzing the Testing Requirements •     Preparing Test Plans, Test Scenarios •     Preparing Test Cases •     Executing the test cases •     Tracking bugs •     Coordinating developers in order to fix it •     Preparing test summary reports •     Reporting quality manager •     Attending meeting\r\n\r\nProjects\r\nProject Name   1.Web Based Time Attendance Application\r\nEnvironment    Windows-7, Vista, Windows XP, Windows 8, Windows 10\r\nClients        MCCIA, Sapphire Park, Bramha Suncity, Wanless hospital\r\nRole           Software Testing\r\nDuration       6 months\r\n\r\nProject Name   Android 1.Time Attendance Application   2.Vehicle Tracking System   3.Vistor Management System\r\nEnvironment    Android Mobile, Android Tablet.\r\nClients        Vankan Security\r\nRole           Application Testing\r\nDuration       6 months\r\n\r\nProject Name   1.Web Based Factory Automation Process   2.Web Based Annual Maintenance Charges\r\nEnvironment    Windows-7, Vista, Windows XP, Windows 8, Windows 10\r\nRole           Software Testing\r\nDuration       6 months\r\n\r\nProject Name   Web Based Library Management System\r\nEnvironment    Windows-7, Vista, Windows XP, Windows 8, Windows 10\r\nRole           Software Testing\r\nDuration       6 months"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: • Proficient in MS office (Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS • Quick learner, • Eagerness t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                             Resume\n",
       "957  Testing  Computer Skills: • Proficient in MS office (Wo...\n",
       "958  Testing  â Willingness to accept the challenges. â ...\n",
       "959  Testing  PERSONAL SKILLS • Quick learner, • Eagerness t...\n",
       "960  Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961  Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cadc91",
   "metadata": {},
   "source": [
    "# Print Number of Rows and Columns in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf0fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  962\n",
      "columns:  2\n"
     ]
    }
   ],
   "source": [
    "print('rows: ', data.shape[0])\n",
    "print('columns: ', data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b0c40",
   "metadata": {},
   "source": [
    " #  Print/Determine all the null columns in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f5f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5f17b251-6541-40ff-8854-9cf3a61b015b",
       "rows": [
        [
         "Category",
         "0"
        ],
        [
         "Resume",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Category    0\n",
       "Resume      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa32796",
   "metadata": {},
   "source": [
    "# Filling null values using mean / median / mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ded78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.fillna(data.mean())\n",
    "#data = data.fillna(data.median())\n",
    "data = data.fillna(data.mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d13e7",
   "metadata": {},
   "source": [
    "# Print datatype of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c10219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "348e6b07-107d-4942-8155-6928f378087b",
       "rows": [
        [
         "Category",
         "object"
        ],
        [
         "Resume",
         "object"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Category    object\n",
       "Resume      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd70676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Resume'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3b2779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d71dbdd7-ed05-4b62-abff-7fbb0ed09893",
       "rows": [
        [
         "Category",
         "25"
        ],
        [
         "Resume",
         "166"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Category     25\n",
       "Resume      166\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2189c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Resume",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "2bab1204-460e-4b57-aa20-f38b289ba746",
       "rows": [
        [
         "0",
         "False",
         "False"
        ],
        [
         "1",
         "False",
         "False"
        ],
        [
         "2",
         "False",
         "False"
        ],
        [
         "3",
         "False",
         "False"
        ],
        [
         "4",
         "False",
         "False"
        ],
        [
         "5",
         "False",
         "False"
        ],
        [
         "6",
         "False",
         "False"
        ],
        [
         "7",
         "False",
         "False"
        ],
        [
         "8",
         "False",
         "False"
        ],
        [
         "9",
         "False",
         "False"
        ],
        [
         "10",
         "False",
         "False"
        ],
        [
         "11",
         "False",
         "False"
        ],
        [
         "12",
         "False",
         "False"
        ],
        [
         "13",
         "False",
         "False"
        ],
        [
         "14",
         "False",
         "False"
        ],
        [
         "15",
         "False",
         "False"
        ],
        [
         "16",
         "False",
         "False"
        ],
        [
         "17",
         "False",
         "False"
        ],
        [
         "18",
         "False",
         "False"
        ],
        [
         "19",
         "False",
         "False"
        ],
        [
         "20",
         "False",
         "False"
        ],
        [
         "21",
         "False",
         "False"
        ],
        [
         "22",
         "False",
         "False"
        ],
        [
         "23",
         "False",
         "False"
        ],
        [
         "24",
         "False",
         "False"
        ],
        [
         "25",
         "False",
         "False"
        ],
        [
         "26",
         "False",
         "False"
        ],
        [
         "27",
         "False",
         "False"
        ],
        [
         "28",
         "False",
         "False"
        ],
        [
         "29",
         "False",
         "False"
        ],
        [
         "30",
         "False",
         "False"
        ],
        [
         "31",
         "False",
         "False"
        ],
        [
         "32",
         "False",
         "False"
        ],
        [
         "33",
         "False",
         "False"
        ],
        [
         "34",
         "False",
         "False"
        ],
        [
         "35",
         "False",
         "False"
        ],
        [
         "36",
         "False",
         "False"
        ],
        [
         "37",
         "False",
         "False"
        ],
        [
         "38",
         "False",
         "False"
        ],
        [
         "39",
         "False",
         "False"
        ],
        [
         "40",
         "False",
         "False"
        ],
        [
         "41",
         "False",
         "False"
        ],
        [
         "42",
         "False",
         "False"
        ],
        [
         "43",
         "False",
         "False"
        ],
        [
         "44",
         "False",
         "False"
        ],
        [
         "45",
         "False",
         "False"
        ],
        [
         "46",
         "False",
         "False"
        ],
        [
         "47",
         "False",
         "False"
        ],
        [
         "48",
         "False",
         "False"
        ],
        [
         "49",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 962
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category  Resume\n",
       "0       False   False\n",
       "1       False   False\n",
       "2       False   False\n",
       "3       False   False\n",
       "4       False   False\n",
       "..        ...     ...\n",
       "957     False   False\n",
       "958     False   False\n",
       "959     False   False\n",
       "960     False   False\n",
       "961     False   False\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df524c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 962 entries, 0 to 961\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  962 non-null    object\n",
      " 1   Resume    962 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2d52a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Resume",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "3068c29d-d255-406f-969a-9df2c5ea68c6",
       "rows": [
        [
         "count",
         "962",
         "962"
        ],
        [
         "unique",
         "25",
         "166"
        ],
        [
         "top",
         "Java Developer",
         "Technical Skills Web Technologies: Angular JS, HTML5, CSS3, SASS, Bootstrap, Jquery, Javascript. Software: Brackets, Visual Studio, Photoshop, Visual Studio Code Education Details \r\nJanuary 2015 B.E CSE Nagpur, Maharashtra G.H.Raisoni College of Engineering\r\nOctober 2009  Photography Competition Click Nagpur, Maharashtra Maharashtra State Board\r\n    College Magazine OCEAN\r\nWeb Designer \r\n\r\nWeb Designer - Trust Systems and Software\r\nSkill Details \r\nPHOTOSHOP- Exprience - 28 months\r\nBOOTSTRAP- Exprience - 6 months\r\nHTML5- Exprience - 6 months\r\nJAVASCRIPT- Exprience - 6 months\r\nCSS3- Exprience - Less than 1 year months\r\nAngular 4- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Trust Systems and Software\r\ndescription - Projects worked on:\r\n1. TrustBank-CBS\r\nProject Description: TrustBank-CBS is a core banking solution by Trust Systems.\r\nRoles and Responsibility:\r\nâ Renovated complete UI to make it more modern, user-friendly, maintainable and optimised for bank use.\r\nâ Shared the UI structure and guidelines to be incorporated, with development team of around 50\r\nmembers.\r\nâ Achieved the target of project completion in given time frame.\r\nâ Made required graphics for the project in photoshop\r\n\r\n2. Loan Bazar (Loan Appraisal)\r\nProject Description: Loan Bazar is a MVC-based application dedicated to creating and managing\r\nloan applications. The goal of this application is to streamline the process of loan application and integrate with existing CBS.\r\nRoles and Responsibility\r\nâ Designed and developed modern and responsive UI of entire application and achieved the target in given time frame.\r\nâ Made required graphics for the project in photoshop\r\n3. Capital Security Bond Application\r\nProject Description: Capital Security Bond Application is a MVC based application which provided an online platform to purchase gold bond\r\nRoles and Responsibility:\r\nâ Designed and developed modern and responsive UI of entire application and achieved the target in given time frame.\r\nâ Made required graphics for the project in photoshop\r\n\r\n4. SoftGST\r\nProject Description: SoftGST (Web Based Application) is an ASP application to every tax\r\npayers and its vendors for generating the GSTR returns on the basis of sales / purchase\r\ndata, additionally the application can do the reconciliation of GSTR 2 A with purchase register.\r\nRoles and Responsibility:\r\nâ Designed and developed the UI of Dashboard.\r\n\r\n5. Trust Analytica:\r\nProject Description: Trust Analytika is the mobile web app that shows bank asset, liability,\r\nincome, expenses.\r\nRoles and Responsibility:\r\nâ Designed and developed the landing page of the application.\r\nâ Supported the developers in UI implementation\r\n\r\n6. Website's:\r\nProject Name:\r\n1. TSR Technology Services - http://tsrtechnologyservices.com\r\n2. Vidarbha Merchants Urban Co-Op Bank - http://vmcbank.com\r\n3. GISSS - http://gisss.co.in\r\n4. Softtrust USA - http://softtrustusa.com\r\nRoles and Responsibility\r\nâ Communicated with clients to understand their requirement\r\nâ Made mocks for the website\r\nâ Designed and developed complete website and hosted them in stipulated time.\r\ncompany - www.jalloshband.com\r\ndescription - Project Name:\r\n1. Jallosh Band - www.jalloshband.com\r\n2. An Endeavor Foundation\r\nRoles and Responsibility:\r\nâ Communicated with clients to understand their requirement\r\nâ Made mocks for the website\r\nâ Designed and developed complete website and hosted them in stipulated time.\r\ncompany - 10MagicalFingers\r\ndescription - National and international client interaction.\r\nâ Management of digital data"
        ],
        [
         "freq",
         "84",
         "18"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Technical Skills Web Technologies: Angular JS,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Category                                             Resume\n",
       "count              962                                                962\n",
       "unique              25                                                166\n",
       "top     Java Developer  Technical Skills Web Technologies: Angular JS,...\n",
       "freq                84                                                 18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c2efe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 962 rows.\n",
      "We have 2 columns.\n"
     ]
    }
   ],
   "source": [
    "print('We have {} rows.'.format(data.shape[0]))\n",
    "print('We have {} columns.'.format(data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a13c6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Resume'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58be2c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.Rameez\\anaconda3\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d3538fab-d1c7-4f37-b003-f0bd60bae56e",
       "rows": [
        [
         "Category",
         "0"
        ],
        [
         "Resume",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Category    0\n",
       "Resume      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isnull(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b47693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science', 'HR', 'Advocate', 'Arts', 'Web Designing',\n",
       "       'Mechanical Engineer', 'Sales', 'Health and fitness',\n",
       "       'Civil Engineer', 'Java Developer', 'Business Analyst',\n",
       "       'SAP Developer', 'Automation Testing', 'Electrical Engineering',\n",
       "       'Operations Manager', 'Python Developer', 'DevOps Engineer',\n",
       "       'Network Security Engineer', 'PMO', 'Database', 'Hadoop',\n",
       "       'ETL Developer', 'DotNet Developer', 'Blockchain', 'Testing'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Resume'].unique()\n",
    "data['Category'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c959d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 962 entries, 0 to 961\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  962 non-null    object\n",
      " 1   Resume    962 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a169f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'â¢': '•'}, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8131c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('read.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bce56db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Resume'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('read.csv')\n",
    "# df.info()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28049216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Category', axis=1)   # Dependant columns / Input columns\n",
    "y = data['Resume']                # Resultant columns / Output column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a32fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.3, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0db981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(673, 1) (673,)\n",
      "(289, 1) (289,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "215f66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07958477508650519\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Dataset\n",
    "# -----------------------------\n",
    "data = pd.read_csv('read.csv')\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Encode Categorical Columns\n",
    "# -----------------------------\n",
    "label_encoders = {}\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':         # If column is categorical\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le          # store encoder (optional)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Split Data\n",
    "# -----------------------------\n",
    "X = data.drop('Category', axis=1)   # Input features\n",
    "y = data['Category']                # Output label\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Train LinearSVC\n",
    "# -----------------------------\n",
    "model = LinearSVC()\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Predictions & Accuracy\n",
    "# -----------------------------\n",
    "pred = model.predict(test_X)\n",
    "acc = accuracy_score(test_y, pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0de78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(round(acc,3)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03a542c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_svc = pickle.load(open('model_svc.pkl', 'rb'))  # Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a7ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_svc, open('model_svc.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
